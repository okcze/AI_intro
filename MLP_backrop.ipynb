{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "attached-nitrogen",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy import random\n",
    "import math\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "tribal-toilet",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predicted_real(predicted, real):\n",
    "    plt.scatter(real, predicted, c='blue')\n",
    "    p1 = max(max(predicted), max(real))\n",
    "    p2 = min(min(predicted), min(real))\n",
    "    plt.plot([p1, p2], [p1, p2], 'b-')\n",
    "    plt.xlabel('True values')\n",
    "    plt.ylabel('Predictions')\n",
    "    plt.title('Predictions visualization on test set')\n",
    "    plt.axis('equal')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "south-quick",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    \"\"\"Funkcja sigmoidalna\"\"\"\n",
    "    return 1/(1 + math.exp(-x))\n",
    "sigmoid = np.vectorize(sigmoid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "unexpected-offense",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid_der(x):\n",
    "    \"\"\"Pochodna funkcji sigmoidalnej\"\"\"\n",
    "    return sigmoid(x)*(1-sigmoid(x))\n",
    "sigmoid_der = np.vectorize(sigmoid_der)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "legitimate-polyester",
   "metadata": {},
   "outputs": [],
   "source": [
    "def MSE(predicted, real):\n",
    "    return np.mean((predicted - real)**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "efficient-blade",
   "metadata": {},
   "outputs": [],
   "source": [
    "def MAE(predicted, real):\n",
    "    return np.mean(np.abs(predicted - real))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "nuclear-helicopter",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Funkcje pmocnicze\n",
    "def normalize(x):\n",
    "    return (x - np.min(x)) / (np.max(x) - np.min(x))\n",
    "\n",
    "def prepear_data(df_train, df_test):\n",
    "    #Separacja wektorów cech i odpowiedzi\n",
    "    x_train, x_test = df_train.iloc[:, 1], df_test.iloc[:, 1]\n",
    "    x_train, x_test = np.array(x_train), np.array(x_test)\n",
    "    #Implementacja wymaga \"pionowego\" wektora cech\n",
    "    x_train.shape = (len(x_train), 1)\n",
    "    x_test.shape = (len(x_test), 1)\n",
    "    y_train, y_test = np.array(df_train.iloc[:, 2:3]), np.array(df_test.iloc[:, 2:3])\n",
    "    #Normalizacja\n",
    "    x_train, x_test = normalize(x_train), normalize(x_test)\n",
    "    y_train, y_test = normalize(y_train), normalize(y_test)\n",
    "    return x_train, y_train, x_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "alert-uzbekistan",
   "metadata": {},
   "outputs": [],
   "source": [
    "###ZMIANY\n",
    "# - wektoryzacja funkcji pomocniczych przy definiowaniu\n",
    "# - oddzielne metody Network predict i forward\n",
    "# - oddzielne metody predict i forward w Layer\n",
    "#   (z lub bez obłożenia funkcją aktywacji)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "suitable-brazilian",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Layer:\n",
    "        \n",
    "    def __init__(self, \n",
    "                 #Liczba neuronów w poprzedzającej i kolejnej warstwie\n",
    "                 input_size: int, \n",
    "                 output_size: int,\n",
    "                 #Domyślna funkcja aktywacyjna i jej pochodna                 \n",
    "                 activation_fun = sigmoid, \n",
    "                 activation_fun_der = sigmoid_der,\n",
    "                 #Parametry rozkładu jednostajnego dla losowych wag\n",
    "                 lb = -1,\n",
    "                 ub = 1,\n",
    "                 #Możliwe do ustawienia wagi i bias-y\n",
    "                 weights = None, \n",
    "                 biases = None):\n",
    "        \n",
    "        #Domyślne losowo wygenerowane wagi i bias-y jeśli nie zostały podane\n",
    "        d_weights = random.uniform(lb, ub, size = (input_size, output_size))\n",
    "        d_biases = random.uniform(lb, ub, size = (1, output_size))\n",
    "        \n",
    "        #Wagi dla wszystkich neuronów z warstwy \n",
    "        self.weights = weights if weights is not None else d_weights\n",
    "        \n",
    "        #Stałe \"b\"\n",
    "        self.biases = biases if biases is not None else d_biases\n",
    "        \n",
    "        #Funkcja aktywacji i jej pochodna\n",
    "        self.activation_fun = activation_fun\n",
    "        self.activation_fun_der = activation_fun_der\n",
    "    \n",
    "    def predict(self, input):\n",
    "        #Przekształca input z poprzedniej warstwy przez wagi i funkcję aktywacji \n",
    "        #Zwraca output do przekazania kolejnej warstwie\n",
    "        return self.activation_fun(input @ self.weights + self.biases)\n",
    "    \n",
    "    def forward(self, input):\n",
    "        #Przekształca input z poprzedniej warstwy jedynie przez wagi\n",
    "        return input @ self.weights + self.biases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "developing-swimming",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network:\n",
    "    \n",
    "    def __init__(self, layers: list):\n",
    "        \n",
    "        #Warstwy\n",
    "        self.layers = layers\n",
    "        \n",
    "    def predict(self, X):\n",
    "        \"\"\"Oblicza output na podstawie danych i parametrów warstw\"\"\"\n",
    "        output = X\n",
    "        for layer in self.layers:\n",
    "            output = layer.predict(output)\n",
    "        return output\n",
    "    \n",
    "    def forward(self, X):\n",
    "        \"\"\"Pełna metoda feedforward\n",
    "        return: sumy, aktywacje\"\"\"\n",
    "        sums = []\n",
    "        activations = [X]\n",
    "        activations_layer = X\n",
    "        for layer in self.layers:\n",
    "            sums_layer = layer.forward(activations_layer)\n",
    "            sums.append(sums_layer)\n",
    "            \n",
    "            activations_layer = layer.activation_fun(sums_layer)\n",
    "            activations.append(activations_layer)\n",
    "            \n",
    "        return sums, activations\n",
    "    \n",
    "    def backprop(self, X, Y):\n",
    "        \"\"\"Propagacja wsteczna błędu\n",
    "        return: gradienty MSE\"\"\"\n",
    "        \n",
    "        #Wyliczenie feedforward obecnymi parametrami\n",
    "        sums, activations = self.forward(X)\n",
    "        \n",
    "        #Macierze na poprawki parametrów\n",
    "        delta_biases = [np.zeros(l.biases.shape) for l in self.layers]\n",
    "        delta_weights = [np.zeros(l.weights.shape) for l in self.layers]\n",
    "        \n",
    "        #Wyliczenie err ostatniej warstwy\n",
    "        err = (activations[-1] - Y)*self.layers[-1].activation_fun_der(sums[-1])\n",
    "        \n",
    "        #Wyliczenie gradientu MSE po parametrach ostatniej warstwy\n",
    "        delta_biases[-1] = err\n",
    "        delta_weights[-1] = activations[-2].transpose()@err\n",
    "        \n",
    "        #Propagacja wsteczna\n",
    "        n_layers = len(self.layers)\n",
    "        \n",
    "        for i in range(n_layers-2, -1, -1):\n",
    "            act_f_der = self.layers[i].activation_fun_der(sums[i])\n",
    "            err = (err@self.layers[i+1].weights.transpose()) * act_f_der \n",
    "            delta_biases[i] = err\n",
    "            delta_weights[i] = np.dot(activations[i-1].transpose(), err)\n",
    "        \n",
    "        return delta_biases, delta_weights\n",
    "    \n",
    "    def train(self, X, Y, k = 1, etha = 0.001, tol = 0.001, verbose = False):\n",
    "        \"\"\"Wytrenowuje sieć wybraną metodą minimalizując MSE \n",
    "        na zbiorze walidacyjnym\"\"\"\n",
    "        \n",
    "        etha = etha/len(X)\n",
    "        \n",
    "        if(k==1):\n",
    "            algorithm = self.gd\n",
    "        else:\n",
    "            algorithm = self.batch_gd\n",
    "        \n",
    "        #Losowość przed podziałem zbioru, ziarno zapewnia identyczną permutację\n",
    "        #w zmiennych objaśnających i zmiennej celu\n",
    "        random.RandomState(42).shuffle(X)\n",
    "        random.RandomState(42).shuffle(Y)\n",
    "        \n",
    "        #Podział zbioru na część walidacyjną i treningową\n",
    "        #proporcje: val 20% - train 80%\n",
    "        X_split = np.split(X, [int(.8 * len(X))])\n",
    "        X_train, X_val = X_split[0], X_split[1]\n",
    "        \n",
    "        Y_split = np.split(Y, [int(.8 * len(Y))])\n",
    "        Y_train, Y_val = Y_split[0], Y_split[1]\n",
    "        \n",
    "        #Właściwe trenowanie sieci\n",
    "        current_mse = np.inf\n",
    "        new_mse = MSE(self.predict(X_val), Y_val)\n",
    "        it = 1\n",
    "        while True:\n",
    "            #Wywołanie konkretnego algorytmu\n",
    "            algorithm(X_train, Y_train, k, etha)\n",
    "            new_mse = MSE(self.predict(X_val), Y_val)\n",
    "            \n",
    "            #Wizualizacja procesu uczenia\n",
    "            if(verbose):\n",
    "                print(\"Current MSE on validation set:\")\n",
    "                print(new_mse)\n",
    "                for i in range(len(self.layers)):\n",
    "                    print(\"Epoche \" + str(it) + \" finished\")\n",
    "                    print(\"Warstwa \" + str(i) + \" wagi:\")\n",
    "                    print(self.layers[i].weights)\n",
    "                    print(\"Warstwa \" + str(i) + \" bias-y:\")\n",
    "                    print(self.layers[i].biases)\n",
    "                print(\"\\n\")\n",
    "            \n",
    "            it += 1\n",
    "            if(current_mse - new_mse > tol):\n",
    "                current_mse = new_mse\n",
    "            else:\n",
    "                break\n",
    "                \n",
    "        print(\"Final MSE on validation set:\")\n",
    "        print(current_mse)\n",
    "        return\n",
    "    \n",
    "    def gd(self, X, Y, k, etha):\n",
    "        \"\"\"Trening sieci podstawową metodą Gradient Descent\"\"\"\n",
    "        delta_biases = [np.zeros(l.biases.shape) for l in self.layers]\n",
    "        delta_weights = [np.zeros(l.weights.shape) for l in self.layers]\n",
    "        \n",
    "        for x, y in zip(X, Y):\n",
    "            b, w = self.backprop(x, y)\n",
    "            delta_biases = [cb-etha*nb for cb, nb in zip(delta_biases, b)]\n",
    "            delta_weights = [cw-etha*nw for cw, nw in zip(delta_weights, w)]\n",
    "        \n",
    "        for i in range(len(self.layers)):\n",
    "            l = self.layers[i]\n",
    "            l.biases = l.biases + delta_biases[i]\n",
    "            l.weights = l.weights + delta_weights[i]\n",
    "        return\n",
    "    \n",
    "    def batch_gd(self, X, Y, k, etha):\n",
    "        \"\"\"Trening sieci metodą Mini-batch Gradient Descent\"\"\"\n",
    "        #Metoda train uprzednio dokonuje permutacji zbioru\n",
    "        #Wystarczy podzielić go na batche\n",
    "        X_split = np.array_split(X, k)\n",
    "        Y_split = np.array_split(Y, k)\n",
    "        \n",
    "        #Wywołanie metody gradient descent na kolejnych batch-ach\n",
    "        for i in range(k):\n",
    "            self.gd(X_split[i], Y_split[i], k, etha)\n",
    "        return\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "satisfactory-queen",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1_train = pd.read_csv(\"./mio1/regression/steps-small-training.csv\")\n",
    "df1_test = pd.read_csv(\"./mio1/regression/steps-small-test.csv\")\n",
    "x_train, y_train, x_test, y_test = prepear_data(df1_train, df1_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "fantastic-fighter",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Utworzenie warst z dobranymi parametrami\n",
    "l1 = Layer(input_size=1, output_size=5, \n",
    "           weights=np.array([[0.75, -0.8, 0.4, -0.7, 0.4]]), \n",
    "           biases=np.array([[-1, -0.9, -0.9, -1, 0.2]]))\n",
    "          \n",
    "l2 = Layer(input_size=5, output_size=1, \n",
    "           activation_fun= lambda x: x, \n",
    "           activation_fun_der= lambda x: 1,\n",
    "           weights = np.array([[40], [40], [35], [35], [0]]),\n",
    "           biases = np.array([[-41.25]]))\n",
    "          \n",
    "\n",
    "#Konstrukcja obiektu sieci i predykcja na danych treningowych i testowych\n",
    "mlp = Network([l1, l2])\n",
    "#pred_train = mlp.forward(x_train)\n",
    "#pred_test = mlp.forward(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "fancy-speaker",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Utworzenie warst z dobranymi parametrami\n",
    "l1 = Layer(input_size=1, output_size=5)\n",
    "#l2 = Layer(input_size=5, output_size=5)\n",
    "#l3 = Layer(input_size=5, output_size=5)\n",
    "l4 = Layer(input_size=5, output_size=1, \n",
    "           activation_fun= lambda x: x, \n",
    "           activation_fun_der= lambda x: 1)          \n",
    "\n",
    "#Konstrukcja obiektu sieci i predykcja na danych treningowych i testowych\n",
    "#mlp = Network([l1, l2, l3, l4])\n",
    "mlp = Network([l1, l4])\n",
    "#pred_train = mlp.forward(x_train)\n",
    "#pred_test = mlp.forward(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "aware-television",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Architektura: 1 warstwa (10 neuronów) losowe parametry\n",
    "l1 = Layer(1, 10)\n",
    "l2 = Layer(10, 1, activation_fun= lambda x: x)\n",
    "\n",
    "mlp = Network([l1, l2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "prostate-reaction",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final MSE on validation set:\n",
      "0.051052430634319065\n"
     ]
    }
   ],
   "source": [
    "mlp.train(x_train, y_train, k=5, etha=10**(-2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "contemporary-integral",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.20029388231027942\n"
     ]
    }
   ],
   "source": [
    "pred_test = mlp.predict(x_test)\n",
    "print(MSE(pred_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "sustained-damages",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "predicted_real(pred_test, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
